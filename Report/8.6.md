### BiLstm
* 对encoder采用BiLstm进行编码，将hidden_state concat后进行dense，效果：可以对encoder的信息增加

### 主题生成
* 采用了LDA的方法对主题进行抽取，之后将生成的keywords喂给encoder


### Skip-thought vector
* 采用两个decoder，因此，对于loss等的计算需要进行学习

### revese
* 对数据集采用revese方法进行encoder，押韵效果提高！